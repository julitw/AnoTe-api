{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llm.LLMAnnotator import LLMAnnotator\n",
    "from llm.models.GPT4omini import GPT4oMiniLLM\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"CLARIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT4oMiniLLM(token=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie przykładowych danych\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"I love this product, it's amazing!\",\n",
    "        \"This is the worst experience I've ever had.\",\n",
    "        \"It's okay, nothing special but not bad either.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = pd.DataFrame(data)\n",
    "\n",
    "# Przykłady do prompta\n",
    "examples_data = {\n",
    "    \"text\": [\n",
    "        \"I really enjoy using this service!\",\n",
    "        \"This is absolutely terrible, I hate it.\"\n",
    "    ],\n",
    "    \"label\": [\"positive\", \"negative\"]\n",
    "}\n",
    "\n",
    "examples_for_prompt = pd.DataFrame(examples_data)\n",
    "\n",
    "# Szablon prompta\n",
    "prompt_template = \"\"\"\n",
    "Based on the following examples:\n",
    "\n",
    "{examples}\n",
    "\n",
    "Classify the following text into one of these categories: {labels}.\n",
    "\n",
    "Text: \"{text}\"\n",
    "Annotation:\n",
    "\"\"\"\n",
    "\n",
    "# Lista etykiet\n",
    "labels = [\"positive\", \"negative\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr:  0 Predicted label:  positive\n",
      "{'text': \"I love this product, it's amazing!\", 'predicted_label': 'positive', 'logprobs': {'content': [{'token': 'positive', 'bytes': [112, 111, 115, 105, 116, 105, 118, 101], 'logprob': -0.008650383912026882, 'top_logprobs': [{'token': 'positive', 'bytes': [112, 111, 115, 105, 116, 105, 118, 101], 'logprob': -0.008650383912026882}, {'token': 'Annotation', 'bytes': [65, 110, 110, 111, 116, 97, 116, 105, 111, 110], 'logprob': -4.758650302886963}, {'token': ' positive', 'bytes': [32, 112, 111, 115, 105, 116, 105, 118, 101], 'logprob': -10.758650779724121}, {'token': ' Annotation', 'bytes': [32, 65, 110, 110, 111, 116, 97, 116, 105, 111, 110], 'logprob': -12.008650779724121}, {'token': 'Positive', 'bytes': [80, 111, 115, 105, 116, 105, 118, 101], 'logprob': -12.258650779724121}]}], 'refusal': None}, 'top_logprobs': [{'token': 'positive', 'bytes': [112, 111, 115, 105, 116, 105, 118, 101], 'logprob': -0.008650383912026882}, {'token': 'Annotation', 'bytes': [65, 110, 110, 111, 116, 97, 116, 105, 111, 110], 'logprob': -4.758650302886963}, {'token': ' positive', 'bytes': [32, 112, 111, 115, 105, 116, 105, 118, 101], 'logprob': -10.758650779724121}, {'token': ' Annotation', 'bytes': [32, 65, 110, 110, 111, 116, 97, 116, 105, 111, 110], 'logprob': -12.008650779724121}, {'token': 'Positive', 'bytes': [80, 111, 115, 105, 116, 105, 118, 101], 'logprob': -12.258650779724121}]}\n",
      "Nr:  1 Predicted label:  negative\n",
      "{'text': \"This is the worst experience I've ever had.\", 'predicted_label': 'negative', 'logprobs': {'content': [{'token': 'negative', 'bytes': [110, 101, 103, 97, 116, 105, 118, 101], 'logprob': -0.0032206105533987284, 'top_logprobs': [{'token': 'negative', 'bytes': [110, 101, 103, 97, 116, 105, 118, 101], 'logprob': -0.0032206105533987284}, {'token': 'Annotation', 'bytes': [65, 110, 110, 111, 116, 97, 116, 105, 111, 110], 'logprob': -5.753220558166504}, {'token': ' negative', 'bytes': [32, 110, 101, 103, 97, 116, 105, 118, 101], 'logprob': -10.753220558166504}, {'token': 'Negative', 'bytes': [78, 101, 103, 97, 116, 105, 118, 101], 'logprob': -10.878220558166504}, {'token': 'positive', 'bytes': [112, 111, 115, 105, 116, 105, 118, 101], 'logprob': -14.378220558166504}]}], 'refusal': None}, 'top_logprobs': [{'token': 'negative', 'bytes': [110, 101, 103, 97, 116, 105, 118, 101], 'logprob': -0.0032206105533987284}, {'token': 'Annotation', 'bytes': [65, 110, 110, 111, 116, 97, 116, 105, 111, 110], 'logprob': -5.753220558166504}, {'token': ' negative', 'bytes': [32, 110, 101, 103, 97, 116, 105, 118, 101], 'logprob': -10.753220558166504}, {'token': 'Negative', 'bytes': [78, 101, 103, 97, 116, 105, 118, 101], 'logprob': -10.878220558166504}, {'token': 'positive', 'bytes': [112, 111, 115, 105, 116, 105, 118, 101], 'logprob': -14.378220558166504}]}\n",
      "Nr:  2 Predicted label:  neutral\n",
      "{'text': \"It's okay, nothing special but not bad either.\", 'predicted_label': 'neutral', 'logprobs': {'content': [{'token': 'neutral', 'bytes': [110, 101, 117, 116, 114, 97, 108], 'logprob': -0.014247537590563297, 'top_logprobs': [{'token': 'neutral', 'bytes': [110, 101, 117, 116, 114, 97, 108], 'logprob': -0.014247537590563297}, {'token': 'Annotation', 'bytes': [65, 110, 110, 111, 116, 97, 116, 105, 111, 110], 'logprob': -4.264247417449951}, {'token': ' neutral', 'bytes': [32, 110, 101, 117, 116, 114, 97, 108], 'logprob': -9.63924789428711}, {'token': 'Neutral', 'bytes': [78, 101, 117, 116, 114, 97, 108], 'logprob': -11.63924789428711}, {'token': 'negative', 'bytes': [110, 101, 103, 97, 116, 105, 118, 101], 'logprob': -13.13924789428711}]}], 'refusal': None}, 'top_logprobs': [{'token': 'neutral', 'bytes': [110, 101, 117, 116, 114, 97, 108], 'logprob': -0.014247537590563297}, {'token': 'Annotation', 'bytes': [65, 110, 110, 111, 116, 97, 116, 105, 111, 110], 'logprob': -4.264247417449951}, {'token': ' neutral', 'bytes': [32, 110, 101, 117, 116, 114, 97, 108], 'logprob': -9.63924789428711}, {'token': 'Neutral', 'bytes': [78, 101, 117, 116, 114, 97, 108], 'logprob': -11.63924789428711}, {'token': 'negative', 'bytes': [110, 101, 103, 97, 116, 105, 118, 101], 'logprob': -13.13924789428711}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "annotator = LLMAnnotator(model, dataset, examples_for_prompt, prompt_template, \"text\", labels)\n",
    "\n",
    "for result in annotator.get_results():\n",
    "    print(json.loads(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anote-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
